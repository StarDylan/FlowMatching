{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StarDylan/FlowMatching/blob/main/StudentNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWFQajdNrCvb",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Install Flow Matching Library\n",
        "!pip install torchcfm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Get MNIST data and format into torch\n",
        "mnist_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "trainset = datasets.MNIST(\n",
        "    \"../data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=mnist_transform,\n",
        ")"
      ],
      "metadata": {
        "id": "uOUGdHh2rJBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataloader with batch size 128\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=128, shuffle=True, drop_last=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "-hEvLLvRrQ-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchcfm.conditional_flow_matching import *\n",
        "from torchcfm.models.unet import UNetModel\n",
        "from torchdyn.core import NeuralODE\n",
        "\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "# Construct a class conditional torchcfm.models.unet UNetModel with 32 channels, 1 residual block and send to GPU\n",
        "# Use the Adam Optimizer\n",
        "# Then initialize the Conditional Flow Matcher with sigma=0."
      ],
      "metadata": {
        "id": "PRdvnWByruZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop, train for 5 epochs\n",
        "for epoch in range(5):\n",
        "    for i, data in enumerate(train_loader):\n",
        "        # Zero Grad\n",
        "\n",
        "        # Get target image and label\n",
        "\n",
        "        # Generate random noise with same shape as target image\n",
        "\n",
        "        # Sample along the optimal transport (straight line) at some t\n",
        "        # (xt) and find the vector to x1 (ut) with\n",
        "        # sample_location_and_conditional_flow\n",
        "\n",
        "        # Run our model and predict a velocity at the sampled point\n",
        "\n",
        "        # MSE Loss\n",
        "\n",
        "        # Backprop and Optimize"
      ],
      "metadata": {
        "id": "xoBh1fvOsEe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torchdiffeq\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.transforms import ToPILImage\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Generate 10 of each class label\n",
        "generated_class_list = torch.arange(10, device=device).repeat(10)\n",
        "\n",
        "\n",
        "# Inference! Use torchdiffeq.odeint to solve the differential equation\n",
        "# with the \"dopri5\" solver,atol=1e-4, rtol=1e-4\n",
        "# Remember the function is our model, conditioned with the class\n",
        "# the initial value is random noise, and the evaluation points are just\n",
        "# equal-spaced points from 0-1\n",
        "\n",
        "\n",
        "\n",
        "# output shape of torchdiffeq.odeint should be: [time steps, # of images, 1 channel, 28, 28]\n",
        "# call this traj\n",
        "\n",
        "# Get the last timestep and display in grid!"
      ],
      "metadata": {
        "id": "GwyZuJzltUko"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}